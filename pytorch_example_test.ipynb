{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baf6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting health outcomes using unlabeled health variables from https://www.kaggle.com/code/gusthema/identifying-age-related-conditions-w-tfdf/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aac1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecf3b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (617, 58)\n",
      "Full test dataset shape is (5, 57)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "rootPath='/Users/Torben/Code/2023Projects/kaggle/ICR/'\n",
    "\n",
    "dataset_df = pd.read_csv(rootPath+'train.csv')\n",
    "test_df = pd.read_csv(rootPath+'test.csv')\n",
    "\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n",
    "print(\"Full test dataset shape is {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9676cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data\n",
    "\n",
    "NUM_FEATURE_COLUMNS = [i for i in dataset_df.columns if i not in [\"Id\", \"EJ\", \"Class\"]]\n",
    "FEATURE_COLUMNS = [i for i in dataset_df.columns if i not in [\"Id\"]]\n",
    "FEATURE_COLUMNS_NO_CLASS = [i for i in dataset_df.columns if i not in [\"Id\",\"Class\"]]\n",
    "\n",
    "TEST_FEATURE_COLUMNS = [i for i in test_df.columns if i not in [\"Id\"]]\n",
    "TEST_FEATURE_COLUMNS_NO_CLASS = [i for i in test_df.columns if i not in [\"Id\",\"Class\"]]\n",
    "\n",
    "nFeatures=len(FEATURE_COLUMNS)-1\n",
    "\n",
    "# remove index 509 because it looks like an incorrect label\n",
    "dataset_df.drop(509)\n",
    "\n",
    "# Create list of ids\n",
    "ID_LIST = dataset_df.index\n",
    "TEST_ID_LIST = test_df.index\n",
    "\n",
    "# Create a dataframe of required size with zero values.\n",
    "oof = pd.DataFrame(data=np.zeros((len(ID_LIST),1)), index=ID_LIST)\n",
    "\n",
    "# Save the name of the label column to a variable.\n",
    "label = \"Class\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb158d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c897fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and normalize data\n",
    "\n",
    "def clean_and_fill(dataset_df, FEATURE_COLUMNS, ID_LIST):\n",
    "    # changes categorical variables to numeric and sets nans to 0\n",
    "    for i in range(len(FEATURE_COLUMNS)):\n",
    "        dataset_df.loc[ dataset_df[FEATURE_COLUMNS[39]] == 'A', FEATURE_COLUMNS[39]] = 0\n",
    "        dataset_df.loc[ dataset_df[FEATURE_COLUMNS[39]] == 'B', FEATURE_COLUMNS[39]] = 1\n",
    "\n",
    "    # fill nans\n",
    "    filled_dataset_df=dataset_df.fillna(0)\n",
    "    \n",
    "    return filled_dataset_df\n",
    "\n",
    "\n",
    "def get_norm_vals(filled_dataset_df, FEATURE_COLUMNS, ID_LIST):\n",
    "    # returns values for mean and std of each column to normalize test data\n",
    "    param_df = pd.DataFrame(data=np.zeros((2,len(FEATURE_COLUMNS))), index=['mean','std'],columns=FEATURE_COLUMNS)\n",
    "\n",
    "    for i in range(len(FEATURE_COLUMNS)):\n",
    "        param_df[FEATURE_COLUMNS[i]]['mean']=np.mean(filled_dataset_df[FEATURE_COLUMNS[i]])\n",
    "        param_df[FEATURE_COLUMNS[i]]['std']=np.std(filled_dataset_df[FEATURE_COLUMNS[i]])\n",
    "\n",
    "    return param_df\n",
    "    \n",
    "def norm_dataset(filled_dataset_df,FEATURE_COLUMNS, ID_LIST, param_df):\n",
    "    # applys normalization parameters to a dataset\n",
    "\n",
    "    normed_df = filled_dataset_df.copy(deep=False)\n",
    "    # # normalize\n",
    "    for i in range(len(FEATURE_COLUMNS)):\n",
    "\n",
    "        if FEATURE_COLUMNS[i] !='Class':\n",
    "            normed = (filled_dataset_df[FEATURE_COLUMNS[i]]-param_df[FEATURE_COLUMNS[i]]['mean']) / param_df[FEATURE_COLUMNS[i]]['std']\n",
    "            normed_df.loc[ID_LIST,FEATURE_COLUMNS[i]]=normed\n",
    "        else:\n",
    "            normed_df.loc[ID_LIST,FEATURE_COLUMNS[i]]=filled_dataset_df.loc[ID_LIST,FEATURE_COLUMNS[i]]\n",
    "\n",
    "    return normed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "917658d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_dataset_df = clean_and_fill(dataset_df,FEATURE_COLUMNS, ID_LIST)\n",
    "param_df = get_norm_vals(filled_dataset_df,FEATURE_COLUMNS, ID_LIST)\n",
    "normed_dataset_df = norm_dataset(filled_dataset_df,FEATURE_COLUMNS, ID_LIST,param_df)\n",
    "\n",
    "filled_test_df = clean_and_fill(test_df,TEST_FEATURE_COLUMNS,TEST_ID_LIST)\n",
    "normed_test_df = norm_dataset(filled_test_df,TEST_FEATURE_COLUMNS,TEST_ID_LIST,param_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "027a4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=normed_dataset_df[FEATURE_COLUMNS_NO_CLASS].astype(np.float32).values\n",
    "y=normed_dataset_df['Class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2e81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self, X_train, y_train):\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "    self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "    # need to convert float64 to Long else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Long but found Float\n",
    "    self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "  def __len__(self):\n",
    "    return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ae0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = Data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf40460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = DataLoader(traindata, batch_size=batch_size, \n",
    "                         shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97f2c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "# number of hidden layers\n",
    "hidden_layers = 25\n",
    "# number of classes (unique of y)\n",
    "output_dim = 2\n",
    "\n",
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Network, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_dim, hidden_layers)\n",
    "    self.linear2 = nn.Linear(hidden_layers, output_dim)\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid(self.linear1(x))\n",
    "    x = self.linear2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3380b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60977b13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85b029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d835308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   155] loss: 0.03323\n",
      "[2,   155] loss: 0.02383\n",
      "[3,   155] loss: 0.01954\n",
      "[4,   155] loss: 0.01746\n",
      "[5,   155] loss: 0.01650\n",
      "[6,   155] loss: 0.01598\n",
      "[7,   155] loss: 0.01462\n",
      "[8,   155] loss: 0.01414\n",
      "[9,   155] loss: 0.01322\n",
      "[10,   155] loss: 0.01292\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    # set optimizer to zero grad to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagation\n",
    "    outputs = clf(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "  # display statistics\n",
    "  print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4eca7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clf(traindata[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1487656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6541,  0.2596], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc513cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bb360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6752f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6391538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02737af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
